# Research: Countermodel Iteration Approaches

## Executive Summary

This document presents research and alternative approaches for understanding and fixing why the ModelChecker's iterator produces invalid countermodels despite correctly preserving all constraints. The iterator SHOULD find multiple countermodels where premises remain true and conclusions remain false at the evaluation world (which may change between models).

## Current State Analysis

### How the Iterator Currently Works

1. **Constraint Preservation**: The iterator correctly preserves ALL constraints:
   - Frame constraints (including that main_world must be a valid world)
   - Model constraints (proposition constraints from the proposition class)
   - Premise constraints (`true_at(premise, main_point)` for each premise)
   - Conclusion constraints (`false_at(conclusion, main_point)` for each conclusion)

2. **Structural Differentiation**: The iterator adds blocking constraints to ensure each new model differs structurally from previous ones

3. **Evaluation World**: The `main_world` is a Z3 variable constrained to be a valid world. Z3 can choose different worlds as the evaluation world in different models, which is acceptable.

### The Mystery

Despite preserving all constraints correctly, MODEL 2+ often have:
- False premises at the evaluation world
- True conclusions at the evaluation world

This violates the premise/conclusion constraints that ARE included in the solver.

### Root Cause Analysis

The issue appears to be a bug or misunderstanding in how the constraints work, NOT a missing constraint. Possible explanations:

1. **Constraint Generation Bug**: The premise_behavior/conclusion_behavior constraints might not be generating what we expect
2. **Model Building Bug**: The model building process might be incorrectly evaluating or displaying truth values
3. **Z3 Interaction Issue**: Something about how we're using Z3 might be causing unexpected behavior
4. **Theory Implementation Bug**: The semantic theories might have bugs in their truth conditions

## Investigation Approaches

### Approach A: Debug Constraint Generation (Recommended)

**Concept**: Add extensive debugging to understand what constraints are actually being generated and why Z3 satisfies them with invalid models.

**Investigation Strategy**:

1. **Trace Constraint Generation**:
   - Print the exact Z3 constraints generated by premise_behavior/conclusion_behavior
   - Verify these constraints match our expectations
   - Check if constraints reference the correct variables

2. **Analyze Z3 Satisfaction**:
   - For each MODEL 2+ that has false premises, check why Z3 thinks the constraints are satisfied
   - Use Z3's proof/unsat core features to understand the solver's reasoning
   - Compare symbolic satisfaction vs semantic evaluation

3. **Debug Points**:
   - In `ModelConstraints.__init__`: Print premise/conclusion constraints
   - In iterator: Print all constraints being added to solver
   - In model evaluation: Compare Z3's view vs our evaluation

**Implementation**:
```python
# Add debug output in ModelConstraints
print(f"[DEBUG] Premise constraint for '{premise}': {constraint}")
print(f"[DEBUG] Main world variable: {self.semantics.main_world}")

# In iterator, verify constraints
for c in self.original_constraints:
    print(f"[DEBUG] Constraint: {c}")
    print(f"[DEBUG] Satisfied in new model: {new_model.eval(c)}")
```

### Approach B: Fix Model Building Process

**Concept**: The bug might be in how we build and evaluate models, not in the constraints themselves.

**Investigation Strategy**:

1. **Verify Model Building**:
   - Check if `_build_new_model_structure` correctly initializes the new model
   - Ensure main_world is properly set from the Z3 model
   - Verify sentence evaluation uses the correct model

2. **Fix Evaluation Chain**:
   - Trace through `true_at` evaluation for a premise that shows as false
   - Check if verify/falsify predicates are evaluated with correct model
   - Ensure no mixing of models during evaluation

3. **Key Areas to Check**:
   - `_initialize_z3_dependent_attributes`: Is main_world set correctly?
   - Proposition evaluation: Does it use the right Z3 model?
   - Truth value display: Is it evaluating with the current model?

### Approach C: Incremental Constraint Debugging

**Concept**: Systematically test the iterator with increasingly complex examples to isolate where the bug occurs.

**Test Strategy**:

1. **Minimal Test Case**:
   - Single atomic premise (A), no conclusion
   - Verify MODEL 2 keeps A true at its evaluation world
   - If this fails, the bug is fundamental

2. **Progressive Complexity**:
   - Add negation (¬A as premise)
   - Add conjunction (A ∧ B as premise)
   - Add modal operators
   - Add conclusions

3. **Constraint Inspection**:
   - For each test, print and manually verify the Z3 constraints
   - Check if the constraints actually enforce what we expect
   - Use Z3's model evaluation to understand satisfaction

### Approach D: Theory-Specific Investigation

**Concept**: The bug might be specific to how certain theories implement their semantics.

**Investigation Strategy**:

1. **Compare Theories**:
   - Test iterator with different theories (logos, exclusion, default)
   - Identify if the bug occurs in all theories or just some
   - Look for patterns in which theories work correctly

2. **Semantic Analysis**:
   - For theories with bugs, examine their `true_at` implementation
   - Check if verify/falsify predicates are correctly defined
   - Verify frame constraints don't interfere with premise/conclusion constraints

3. **Focus Areas**:
   - Hyperintensional theories (logos, exclusion): Complex verify/falsify semantics
   - Modal theories: Accessibility relations might interfere
   - Counterfactual theories: Complex evaluation conditions

## Recommendation

**Recommended Approach: A (Debug Constraint Generation)**

This is the most direct path to understanding and fixing the issue:
- Start with debugging to understand the exact nature of the bug
- Minimal risk since we're just adding instrumentation
- Will reveal whether the issue is in constraint generation, model building, or theory implementation

**Implementation Timeline: 2-3 days for investigation, 2-3 days for fix**

## Systematic Debugging Plan

Following the debugging protocol from the Style Guide, this plan starts with non-invasive investigation using existing tools, then proceeds to targeted code modifications if needed.

### Phase 1: Initial Investigation (No Code Changes)

#### 1.1 Create Debug Analysis Document

```bash
mkdir -p docs/specs/debug
touch docs/specs/debug/001_iterator_constraint_analysis.md
```

Document structure:
```markdown
# Debug Analysis 001: Iterator Constraint Preservation Issue

## Issue Summary
Iterator produces MODEL 2+ with false premises despite preserving all constraints

## Investigation Log
### Phase 1: Non-invasive Analysis
### Phase 2: Code Instrumentation (if needed)

## Test Cases
### Test 1: Minimal Atomic Premise
### Test 2: Negated Premise  
### Test 3: Complex Formula

## Findings
### Constraint Analysis
### Z3 Model Comparison
### Root Cause

## Solution & Verification
```

#### 1.2 Test with Existing Tools

1. **Create minimal test script** `test_minimal_iterator.py`:
   ```python
   from model_checker import get_theory, BuildExample
   
   # Test 1: Single atomic premise
   theory = get_theory('logos')
   ex1 = BuildExample("test1", theory, 
                      premises=['A'], 
                      conclusions=[],
                      settings={'N': 2, 'iterate': 2})
   ```

2. **Run with debug flags**:
   ```bash
   ./dev_cli.py test_minimal_iterator.py -z -p > debug_output.txt
   ```

3. **Analyze output**:
   ```bash
   # Extract constraints
   grep -E "constraint|Premise|Conclusion" debug_output.txt > constraints.txt
   
   # Compare MODEL 1 vs MODEL 2
   grep -A30 "MODEL 1/2" debug_output.txt > model1.txt
   grep -A30 "MODEL 2/2" debug_output.txt > model2.txt
   ```

#### 1.3 Constraint Verification Script

Create `verify_constraints.py` to check constraint satisfaction:
```python
import z3
from model_checker import get_theory, BuildExample

theory = get_theory('logos')
ex = BuildExample("verify", theory,
                  premises=['A'],
                  conclusions=[],
                  settings={'N': 2, 'iterate': 2})

# Check if we can access iterator info
if hasattr(ex, '_iterator') and len(ex._iterator.found_models) > 1:
    model1 = ex._iterator.found_models[0]
    model2 = ex._iterator.found_models[1]
    
    print("Checking constraint satisfaction in MODEL 2:")
    for i, c in enumerate(ex.model_constraints.all_constraints):
        try:
            sat = model2.eval(c, model_completion=True)
            print(f"Constraint {i}: {sat}")
        except:
            print(f"Constraint {i}: Could not evaluate")
```

### Phase 2: Targeted Code Instrumentation (If Needed)

If Phase 1 doesn't reveal the issue, proceed with minimal, targeted code changes:

#### 2.1 Create Debug Branch

```bash
git checkout -b debug/iterator-constraints
git commit -m "Checkpoint before debug instrumentation"
```

#### 2.2 Add Strategic Debug Points

1. **Instrument constraint generation** in `ModelConstraints.__init__`:
   ```python
   # Temporary debug code - REMOVE AFTER INVESTIGATION
   print(f"[DEBUG] === Constraint Generation ===")
   print(f"[DEBUG] Main world variable: {self.semantics.main_world}")
   print(f"[DEBUG] Frame constraints: {len(self.frame_constraints)}")
   
   for i, premise in enumerate(self.premises):
       constraint = self.semantics.premise_behavior(premise)
       print(f"[DEBUG] Premise {i} '{premise}':")
       print(f"[DEBUG]   Constraint: {constraint}")
       print(f"[DEBUG]   Type: {type(constraint)}")
   ```

2. **Instrument iterator constraint preservation** in `core.py`:
   ```python
   # In _create_extended_constraints
   # Temporary debug code - REMOVE AFTER INVESTIGATION
   print(f"[DEBUG] === Iterator Constraints ===")
   print(f"[DEBUG] Preserved {len(self.original_constraints)} constraints")
   
   # Find premise/conclusion constraints
   for i, c in enumerate(self.original_constraints):
       c_str = str(c)
       if 'true_at' in c_str or 'false_at' in c_str:
           print(f"[DEBUG] Constraint {i} (premise/conclusion): {c}")
   ```

3. **Instrument model evaluation** in theory's `print_semantics`:
   ```python
   # Temporary debug code - REMOVE AFTER INVESTIGATION
   print(f"[DEBUG] === Model Evaluation ===")
   print(f"[DEBUG] Evaluation world: {self.main_point['world']}")
   print(f"[DEBUG] Z3 says world is: {self.z3_model.eval(self.main_world)}")
   
   # For each premise, check constraint satisfaction
   for premise in self.premises:
       constraint = self.semantics.premise_behavior(premise)
       sat = self.z3_model.eval(constraint, model_completion=True)
       print(f"[DEBUG] Premise '{premise}' constraint satisfied: {sat}")
   ```

#### 2.3 Run Instrumented Code

```bash
# Run minimal test with instrumentation
./dev_cli.py test_minimal_iterator.py > debug_instrumented.txt 2>&1

# Capture specific debug output
grep "[DEBUG]" debug_instrumented.txt > debug_analysis.txt
```

#### 2.4 Deep Constraint Analysis

If needed, add more specific instrumentation:

1. **Trace true_at evaluation**:
   ```python
   # In semantic.py true_at method
   # Temporary debug code - REMOVE AFTER INVESTIGATION
   def true_at(self, sentence, eval_point):
       result = # ... existing code ...
       if hasattr(self, '_debug_mode'):
           print(f"[DEBUG] true_at({sentence}, {eval_point['world']}) = {result}")
       return result
   ```

2. **Compare Z3 model values**:
   ```python
   # In iterator after finding new model
   # Temporary debug code - REMOVE AFTER INVESTIGATION
   print(f"[DEBUG] === Z3 Model Comparison ===")
   for var in [self.build_example.model_structure.main_world]:
       val1 = self.found_models[0].eval(var)
       val2 = new_model.eval(var)
       print(f"[DEBUG] {var}: MODEL1={val1}, MODEL2={val2}")
   ```

### Phase 3: Root Cause Analysis & Fix

#### 3.1 Document Findings

1. **Update debug analysis document** `docs/specs/debug/001_iterator_constraint_analysis.md` with:
   - Exact constraint that's violated (if any)
   - Discrepancy between Z3 and semantic evaluation
   - Root cause identification

2. **Create consolidated findings document** `docs/specs/findings/019_iterator_constraint_preservation.md`:
   ```markdown
   # Finding 019: Iterator Constraint Preservation Issue
   
   ## Summary
   Iterator produces MODEL 2+ with false premises and true conclusions despite preserving all constraints.
   
   ## Problem Description
   [Detailed description from investigation]
   
   ## Root Cause
   [Specific code or design issue identified]
   
   ## Solution
   [Implemented fix with code snippets]
   
   ## Verification
   - Test cases used
   - Results before and after fix
   
   ## Lessons Learned
   [Key insights for future development]
   
   ## Related Issues
   - Finding 017: MODEL 2 Empty Verifiers/Falsifiers
   - Finding 018: Iterator Model vs Countermodel Behavior
   ```

#### 3.2 Implement Minimal Fix

1. **Create fix on debug branch**:
   ```python
   # Implement targeted fix based on findings
   # Keep debug output initially to verify fix
   ```

2. **Verify fix**:
   ```bash
   # Run all iterator examples
   ./run_tests.py --examples | grep -E "MODEL|premise|conclusion"
   ```

#### 3.3 Clean Up and Finalize

1. **Remove all debug code**:
   ```bash
   # Remove all lines containing "DEBUG" and "REMOVE AFTER"
   grep -r "REMOVE AFTER" src/ | cut -d: -f1 | sort -u | xargs -I {} sed -i '/REMOVE AFTER/,/^$/d' {}
   ```

2. **Create clean fix commit**:
   ```bash
   git add -A
   git commit -m "Fix: Iterator constraint preservation issue

   - Root cause: [describe]
   - Solution: [describe]
   - Verified with: [test cases]
   
   See docs/specs/findings/019_iterator_constraint_preservation.md"
   ```

3. **Optional: Cherry-pick to main branch**:
   ```bash
   git checkout main
   git cherry-pick [fix-commit-hash]
   ```

## Success Criteria

The investigation is complete when:
1. We understand exactly why Z3 produces models with false premises
2. We have identified the specific code that needs to be fixed
3. We can reliably reproduce the issue with a minimal test case
4. We have a clear fix that makes all MODEL 2+ valid countermodels

## Fallback Plan

If the debugging approach doesn't reveal the issue within 3 days, implement a workaround:
1. Add post-model validation that checks premise/conclusion truth values
2. If invalid, add explicit constraints and retry
3. Document this as a temporary fix while continuing investigation

## Conclusion

The iterator's current design is sound - it preserves all necessary constraints. The issue is likely a bug in implementation rather than a fundamental design flaw. By systematically debugging the constraint generation and model evaluation process, we can identify and fix the root cause while maintaining the elegant architecture of the current system.
